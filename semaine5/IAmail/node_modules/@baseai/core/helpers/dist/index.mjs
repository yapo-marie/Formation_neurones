// src/helpers/stream.ts
import { ChatCompletionStream } from "openai/lib/ChatCompletionStream";
import { Stream } from "openai/streaming";
var fromReadableStream = (readableStream) => {
  return ChatCompletionStream.fromReadableStream(readableStream);
};
var getRunner = (readableStream) => {
  return fromReadableStream(readableStream);
};
var getTextPart = (chunk) => {
  var _a, _b;
  return ((_b = (_a = chunk.choices[0]) == null ? void 0 : _a.delta) == null ? void 0 : _b.content) || "";
};
function handleResponseStream({
  response,
  rawResponse
}) {
  const controller = new AbortController();
  const streamSSE = Stream.fromSSEResponse(response, controller);
  const stream = streamSSE.toReadableStream();
  const result = {
    stream,
    threadId: response.headers.get("lb-thread-id")
  };
  if (rawResponse) {
    result.rawResponse = {
      headers: Object.fromEntries(response.headers.entries())
    };
  }
  return result;
}
async function getToolsFromStream(stream) {
  let run = getRunner(stream);
  const { choices } = await run.finalChatCompletion();
  return choices[0].message.tool_calls;
}
export {
  fromReadableStream,
  getRunner,
  getTextPart,
  getToolsFromStream,
  handleResponseStream
};
//# sourceMappingURL=index.mjs.map